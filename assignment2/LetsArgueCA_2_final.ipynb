{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09ba900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(name='en_core_web_sm')\n",
    "\n",
    "df = pd.read_csv('./data/train-bio.csv', sep='\\t', header=None)\n",
    "df.columns = ['tokens','BIO_Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "X,y = df['tokens'],df['BIO_Label']\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(X)):\n",
    "    review = re.sub(r'\\W', ' ', str(X[i]))\n",
    "    review = review.lower()\n",
    "    review = re.sub(r'\\s+[a-z]\\s+', ' ',review) #substitute all single characters with space on l&r\n",
    "    review = re.sub(r'\\s+', ' ', review)  #substitute all spaces to single space\n",
    "    corpus.append(review) \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features = 2000, min_df = 3, max_df = 0.6, stop_words = stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(corpus).toarray()\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "text_train, text_test, sent_train, sent_test = train_test_split(X[0:2000], y[0:2000], test_size = 0.20, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2662f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6783333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.00      0.00      0.00        23\n",
      "           I       0.73      0.86      0.79       398\n",
      "           O       0.55      0.36      0.43       179\n",
      "\n",
      "    accuracy                           0.68       600\n",
      "   macro avg       0.43      0.41      0.41       600\n",
      "weighted avg       0.65      0.68      0.65       600\n",
      "\n",
      "   B    I   O\n",
      "B  0   19   4\n",
      "I  6  343  49\n",
      "O  6  109  64\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import load_files\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "df_shuffled = df.sample(frac=1).reset_index(drop=True) #shuffle your dataframe in-place and reset the index, only sample will also work\n",
    "\n",
    "df_shuffled = df_shuffled.iloc[:3000]\n",
    "\n",
    "for token,biolabel in df_shuffled.itertuples(index=False):\n",
    "    if str(token) not in stopwords.words('english'):\n",
    "        token = re.sub(r'\\W', ' ', str(token))\n",
    "        token = token.lower()\n",
    "        token = re.sub(r'\\s+[a-z]\\s+', ' ',token) #substitute all single characters with space on l&r\n",
    "        token = re.sub(r'\\s+', ' ', token)  #substitute all spaces to single space\n",
    "        # we have to remove empty token which are being generated by substituting\n",
    "\n",
    "df_shuffled.isnull().sum() \n",
    "df_shuffled.dropna(inplace=True)\n",
    "\n",
    "def get_vec(x):\n",
    "    doc = nlp(str(x))\n",
    "    vec = doc.vector\n",
    "    return vec\n",
    "\n",
    "df_shuffled['vec'] = df_shuffled['tokens'].apply(lambda x: get_vec(x))\n",
    "\n",
    "X = df_shuffled['vec'].to_numpy()\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "X = np.concatenate(np.concatenate(X, axis = 0), axis = 0).reshape(-1, 300)\n",
    "\n",
    "y = df_shuffled['BIO_Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)\n",
    "\n",
    "# clf = LinearSVC()\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train)\n",
    "svm_predictions = svm_model_linear.predict(X_test)\n",
    "accuracy = svm_model_linear.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "print(metrics.classification_report(y_test, svm_predictions))\n",
    "cm = confusion_matrix(y_test, svm_predictions)\n",
    "\n",
    "# dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train)\n",
    "# dtree_predictions = dtree_model.predict(X_test)\n",
    "# accuracy = dtree_model.score(X_test, y_test)\n",
    "# print(accuracy)\n",
    "# print(metrics.classification_report(y_test, dtree_predictions))\n",
    "# cm = confusion_matrix(y_test, dtree_predictions)\n",
    "\n",
    "# naive_bayes_model = GaussianNB().fit(X_train, y_train)\n",
    "# naive_bayes_predictions = naive_bayes_model.predict(X_test)\n",
    "# accuracy = naive_bayes_model.score(X_test, y_test)\n",
    "# print(accuracy)\n",
    "# print(metrics.classification_report(y_test, naive_bayes_predictions))\n",
    "# cm = confusion_matrix(y_test, naive_bayes_predictions)\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(cm,index=['B','I','O'], columns=['B','I','O'])\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "08f2332d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>BIO_Label</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mobile</td>\n",
       "      <td>I</td>\n",
       "      <td>[-0.14581, 0.36688, 0.31404, 0.33013, 0.55531,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not</td>\n",
       "      <td>I</td>\n",
       "      <td>[-0.04983, 0.02705, -0.38787, -0.25857, -0.019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>I</td>\n",
       "      <td>[0.31924, 0.06316, -0.27858, 0.2612, 0.079248,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doubt</td>\n",
       "      <td>O</td>\n",
       "      <td>[-0.1683, 0.070158, -0.20011, -0.16466, -0.054...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>community</td>\n",
       "      <td>I</td>\n",
       "      <td>[0.2045, 0.22617, 0.040692, 0.00032489, 0.2187...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tokens BIO_Label                                                vec\n",
       "0     mobile         I  [-0.14581, 0.36688, 0.31404, 0.33013, 0.55531,...\n",
       "1        not         I  [-0.04983, 0.02705, -0.38787, -0.25857, -0.019...\n",
       "2         to         I  [0.31924, 0.06316, -0.27858, 0.2612, 0.079248,...\n",
       "3      doubt         O  [-0.1683, 0.070158, -0.20011, -0.16466, -0.054...\n",
       "4  community         I  [0.2045, 0.22617, 0.040692, 0.00032489, 0.2187..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b09fa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#here we will predict for test-bio\n",
    "import pandas as pd\n",
    "df_abc = pd.read_csv('./data/test-bio.csv', sep='\\t', header=None)\n",
    "df_abc.columns = ['tokens','BIO_Label']\n",
    "\n",
    "df_abc.head()\n",
    "\n",
    "svm_predictions = svm_model_linear.predict('sahil')\n",
    "# print(metrics.classification_report(df_abc['BIO_Label'], svm_predictions))\n",
    "# cm = confusion_matrix(df_abc['BIO_Label'], svm_predictions)\n",
    "# print(cm)\n",
    "\n",
    "# accuracy = svm_model_linear.score(X_test, y_test)\n",
    "# print(accuracy)\n",
    "# print(metrics.classification_report(y_test, svm_predictions))\n",
    "# cm = confusion_matrix(y_test, svm_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
